{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fe35f23-8d46-4887-915d-d7399f299482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/awlego/Repositories/lc0/env3.10/bin/python\n"
     ]
    }
   ],
   "source": [
    "# make sure that this is the expected virtual env\n",
    "!which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1af18-ba00-4f1a-b658-b53049745528",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1a9d76-0d6e-4655-a193-db274dbb8e92",
   "metadata": {},
   "source": [
    "Install Leela Chess Zero for my system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea73b60-f3fd-4d81-9850-6aa79e32ed2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./env3.10/lib/python3.10/site-packages (1.26.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: scikit-learn in ./env3.10/lib/python3.10/site-packages (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./env3.10/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./env3.10/lib/python3.10/site-packages (from scikit-learn) (1.11.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./env3.10/lib/python3.10/site-packages (from scikit-learn) (1.26.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./env3.10/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorflow in ./env3.10/lib/python3.10/site-packages (2.14.0)\n",
      "Requirement already satisfied: tensorflow-macos==2.14.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.26.1)\n",
      "Requirement already satisfied: six>=1.12.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (4.8.0)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: setuptools in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (65.4.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.34.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.20.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (3.10.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in ./env3.10/lib/python3.10/site-packages (from tensorflow-macos==2.14.0->tensorflow) (2.14.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./env3.10/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow-macos==2.14.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./env3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./env3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.5)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in ./env3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./env3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in ./env3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.23.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env3.10/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./env3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./env3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./env3.10/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./env3.10/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env3.10/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./env3.10/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in ./env3.10/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./env3.10/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow-macos==2.14.0->tensorflow) (3.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement gzip (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for gzip\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tf2onnx in ./env3.10/lib/python3.10/site-packages (1.15.1)\n",
      "Requirement already satisfied: numpy>=1.14.1 in ./env3.10/lib/python3.10/site-packages (from tf2onnx) (1.26.1)\n",
      "Requirement already satisfied: requests in ./env3.10/lib/python3.10/site-packages (from tf2onnx) (2.31.0)\n",
      "Requirement already satisfied: onnx>=1.4.1 in ./env3.10/lib/python3.10/site-packages (from tf2onnx) (1.14.1)\n",
      "Requirement already satisfied: six in ./env3.10/lib/python3.10/site-packages (from tf2onnx) (1.16.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in ./env3.10/lib/python3.10/site-packages (from tf2onnx) (23.5.26)\n",
      "Requirement already satisfied: protobuf~=3.20.2 in ./env3.10/lib/python3.10/site-packages (from tf2onnx) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in ./env3.10/lib/python3.10/site-packages (from onnx>=1.4.1->tf2onnx) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env3.10/lib/python3.10/site-packages (from requests->tf2onnx) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env3.10/lib/python3.10/site-packages (from requests->tf2onnx) (2.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env3.10/lib/python3.10/site-packages (from requests->tf2onnx) (3.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env3.10/lib/python3.10/site-packages (from requests->tf2onnx) (2023.7.22)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: onnx in ./env3.10/lib/python3.10/site-packages (1.14.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.2.1 in ./env3.10/lib/python3.10/site-packages (from onnx) (4.8.0)\n",
      "Requirement already satisfied: numpy in ./env3.10/lib/python3.10/site-packages (from onnx) (1.26.1)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./env3.10/lib/python3.10/site-packages (from onnx) (3.20.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: onnxruntime in ./env3.10/lib/python3.10/site-packages (1.16.1)\n",
      "Requirement already satisfied: protobuf in ./env3.10/lib/python3.10/site-packages (from onnxruntime) (3.20.3)\n",
      "Requirement already satisfied: sympy in ./env3.10/lib/python3.10/site-packages (from onnxruntime) (1.12)\n",
      "Requirement already satisfied: coloredlogs in ./env3.10/lib/python3.10/site-packages (from onnxruntime) (15.0.1)\n",
      "Requirement already satisfied: numpy>=1.21.6 in ./env3.10/lib/python3.10/site-packages (from onnxruntime) (1.26.1)\n",
      "Requirement already satisfied: flatbuffers in ./env3.10/lib/python3.10/site-packages (from onnxruntime) (23.5.26)\n",
      "Requirement already satisfied: packaging in ./env3.10/lib/python3.10/site-packages (from onnxruntime) (23.2)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./env3.10/lib/python3.10/site-packages (from coloredlogs->onnxruntime) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./env3.10/lib/python3.10/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in ./env3.10/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: pillow>=8 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (10.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./env3.10/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in ./env3.10/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: python-chess in ./env3.10/lib/python3.10/site-packages (1.999)\n",
      "Requirement already satisfied: chess<2,>=1 in ./env3.10/lib/python3.10/site-packages (from python-chess) (1.10.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tqdm in ./env3.10/lib/python3.10/site-packages (4.66.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: nimfa in ./env3.10/lib/python3.10/site-packages (1.4.0)\n",
      "Requirement already satisfied: numpy>=1.7.0 in ./env3.10/lib/python3.10/site-packages (from nimfa) (1.26.1)\n",
      "Requirement already satisfied: scipy>=0.12.0 in ./env3.10/lib/python3.10/site-packages (from nimfa) (1.11.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: cairosvg in ./env3.10/lib/python3.10/site-packages (2.7.1)\n",
      "Requirement already satisfied: defusedxml in ./env3.10/lib/python3.10/site-packages (from cairosvg) (0.7.1)\n",
      "Requirement already satisfied: tinycss2 in ./env3.10/lib/python3.10/site-packages (from cairosvg) (1.2.1)\n",
      "Requirement already satisfied: pillow in ./env3.10/lib/python3.10/site-packages (from cairosvg) (10.1.0)\n",
      "Requirement already satisfied: cssselect2 in ./env3.10/lib/python3.10/site-packages (from cairosvg) (0.7.0)\n",
      "Requirement already satisfied: cairocffi in ./env3.10/lib/python3.10/site-packages (from cairosvg) (1.7.1)\n",
      "Requirement already satisfied: cffi>=1.1.0 in ./env3.10/lib/python3.10/site-packages (from cairocffi->cairosvg) (1.16.0)\n",
      "Requirement already satisfied: webencodings in ./env3.10/lib/python3.10/site-packages (from cssselect2->cairosvg) (0.5.1)\n",
      "Requirement already satisfied: pycparser in ./env3.10/lib/python3.10/site-packages (from cffi>=1.1.0->cairocffi->cairosvg) (2.21)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: Pillow in ./env3.10/lib/python3.10/site-packages (10.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# /opt/homebrew/bin/lc0\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow\n",
    "!pip install gzip\n",
    "!pip install tf2onnx\n",
    "!pip install onnx\n",
    "!pip install onnxruntime\n",
    "!pip install matplotlib\n",
    "!pip install python-chess\n",
    "!pip install tqdm\n",
    "!pip install nimfa\n",
    "!pip install cairosvg\n",
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb808cd8-7aa4-45e8-ab76-9ec6b384b9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/awlego/Repositories/lc0/env3.10/lib/python3.10/site-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "from sklearn.decomposition import NMF\n",
    "import gzip\n",
    "import onnx\n",
    "from lczero.backends import Weights, Backend, GameState\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import chess\n",
    "import chess.svg\n",
    "import onnxruntime as ort\n",
    "from tqdm import tnrange, tqdm_notebook\n",
    "from collections import OrderedDict\n",
    "import tqdm\n",
    "import pickle\n",
    "from PIL import Image\n",
    "import cairosvg\n",
    "import io\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10090e66-4460-4f86-b496-a22dca17e9c2",
   "metadata": {},
   "source": [
    "## chess model paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b190578e-446e-4e12-a231-793d8a708901",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lc0_model_path = \"/opt/homebrew/Cellar/lc0/0.30.0/libexec/42850.pb.gz\"\n",
    "onnx_path = \"/opt/homebrew/Cellar/lc0/0.30.0/libexec/42850.onnx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acb79bf-547c-446c-a017-c9dceb103dac",
   "metadata": {},
   "source": [
    "I converted the Lc0 model to onnx so that I can load the model and treat mid-model layers as outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5bccb3-2ee7-4eda-9049-b31fe2977493",
   "metadata": {},
   "source": [
    "## Testing loading the model and getting something out of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2023991-41b2-4d54-bcf8-795cd80ff885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 112, 8, 8)\n",
      "[array([[-5265.6606 , -8108.749  ,  3693.3042 , ...,   495.45285,\n",
      "        -5423.0835 , -3413.9202 ]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "sess_options = ort.SessionOptions()\n",
    "sess = ort.InferenceSession(onnx_path, sess_options)\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_name = sess.get_outputs()[0].name\n",
    "\n",
    "# Here's a dummy input for demonstration.\n",
    "dummy_input_data = np.random.randn(1, 112, 8, 8).astype(np.float32)\n",
    "print(dummy_input_data.shape)\n",
    "\n",
    "predictions = sess.run([output_name], {input_name: dummy_input_data})\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6ade0-d659-459f-b288-17cab3403d7e",
   "metadata": {},
   "source": [
    "okay I can look at my onnx model in netron.app and see it looks right -- I see 15 blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30810e52-c95e-4b2d-903f-1f35748bed23",
   "metadata": {},
   "source": [
    "## Test Lc0 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "effc9b31-03e9-426c-a79c-3ba6c3b5ef26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rnbqkbnr\n",
      "pppppppp\n",
      "........\n",
      "........\n",
      "........\n",
      "........\n",
      "PPPPPPPP\n",
      "RNBQKBNR KQkq[AHah] (from white's eyes) Hash: 2326312736498822375\n",
      "\n",
      "rnbqkbnr\n",
      "pppp.ppp\n",
      "........\n",
      "....p...\n",
      "....P...\n",
      "........\n",
      "PPPP.PPP\n",
      "RNBQKBNR KQkq[AHah] (from white's eyes) Hash: 8572518730975593504\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating backend [metal]...\n",
      "Initialized metal backend on device Apple M1 Max\n"
     ]
    }
   ],
   "source": [
    "new_board_fen = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "e4e5_board_fen = \"rnbqkbnr/pppp1ppp/8/4p3/4P3/8/PPPP1PPP/RNBQKBNR w KQkq - 0 2\"\n",
    "\n",
    "w = Weights(Lc0_model_path)\n",
    "b = Backend(weights=w)\n",
    "g = GameState(new_board_fen)\n",
    "print(g.as_string())\n",
    "g2 = GameState(e4e5_board_fen)\n",
    "print(g2.as_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb77779-509b-47b6-95ab-50b16ee143d9",
   "metadata": {},
   "source": [
    "Great, looks like I can get a model loaded with the lc0 backend\n",
    "\n",
    "## PLAN:\n",
    " - [x] encode a board state from a FEN into the format the the model takes\n",
    " - [x] write something to translate the output into top 3 moves\n",
    " - [x] run the model on a new game and an e4e5 game to validate that the predictions match the chess engine version I have\n",
    " - [x] do the nmf stuff\n",
    " - [x] visualize the output\n",
    " - [x] find a way to publish output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c81fd-76e8-4391-82b1-6aee75c3c122",
   "metadata": {},
   "source": [
    "## Encoding board state from FEN -> format model takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462c0cfa-0fab-4a34-8f77-38410b025b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This should be our pawns\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 1 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "1 1 1 1 0 1 1 1\n",
      "0 0 0 0 0 0 0 0\n",
      "This should be our knights\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 0 0 0 0 0 0 0\n",
      "0 1 0 0 0 0 1 0\n"
     ]
    }
   ],
   "source": [
    "def print_binary_as_8x8(number):\n",
    "    # Convert the number to a binary string, removing the '0b' prefix, and pad with leading zeros\n",
    "    binary_string = format(number, '064b')\n",
    "    # Split the binary string into 8-character chunks\n",
    "    rows = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
    "    # flip the bits in the row because the first bit the bottom left not bottom right\n",
    "    rows = [row[::-1] for row in rows]\n",
    "    # Print each row to form the 8x8 grid\n",
    "    for row in rows:\n",
    "        print(' '.join(row))\n",
    "\n",
    "print(\"This should be our pawns\")\n",
    "print_binary_as_8x8(g2.as_input(b).mask(0))\n",
    "print(\"This should be our knights\")\n",
    "print_binary_as_8x8(g2.as_input(b).mask(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85facae-9e49-4385-9e80-72be5d0bc79c",
   "metadata": {},
   "source": [
    "okay, so now I need to figure out how to shape this into the shape of the input from my model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac52df0-3cb3-48c5-b22e-d7100d7e76eb",
   "metadata": {},
   "source": [
    "Looking at encoder.cc, weights.h, and bitboard.h in the LC0 source code:\n",
    "According to Leela there are 112 layers with 8x8 masks (this matches netron's claim of 112x8x8)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c844ce08-beea-4755-8710-5954bfedc97d",
   "metadata": {},
   "source": [
    "looks like they incode various info into a bunch of planes with masks... stuff like which pieces, castling info, etc\n",
    "relevant snippits:\n",
    "```\n",
    "InputPlanes EncodePositionForNN(\n",
    "    pblczero::NetworkFormat::InputFormat input_format,\n",
    "    const PositionHistory& history, int history_planes,\n",
    "    FillEmptyHistory fill_empty_history, int* transform_out) {\n",
    "  InputPlanes result(kAuxPlaneBase + 8);\n",
    "```\n",
    "```\n",
    "// Represents a board as an array of 64 bits.\n",
    "// Bit enumeration goes from bottom to top, from left to right:\n",
    "// Square a1 is bit 0, square a8 is bit 7, square b1 is bit 8.\n",
    "class BitBoard {\n",
    " public:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3338d7da-36e2-4045-ac1d-2c82dd304274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mask_to_plane(mask):\n",
    "    # Convert to binary string, strip off the '0b' prefix, and pad to 64 bits\n",
    "    binary_string = bin(mask)[2:].zfill(64)\n",
    "    rows = [binary_string[i:i+8] for i in range(0, len(binary_string), 8)]\n",
    "    rows = [row[::-1] for row in rows]\n",
    "    rows.reverse()\n",
    "\n",
    "    plane = np.array([[float(bit) for bit in row] for row in rows])\n",
    "    return plane\n",
    "\n",
    "def game_state_to_input_data(game_state, backend):\n",
    "    # Create an empty array of shape (112, 8, 8)\n",
    "    board_planes = np.zeros((112, 8, 8), dtype=np.float32)\n",
    "\n",
    "    for i in range(112):\n",
    "        board_planes[i] = mask_to_plane(game_state.as_input(backend).mask(i))\n",
    "    # Add a batch dimension\n",
    "    input_data = board_planes[np.newaxis, :]\n",
    "\n",
    "    return input_data\n",
    "\n",
    "input_data = game_state_to_input_data(g2, b)\n",
    "input_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "950dda78-6e87-468d-9c2c-7a8794299144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1858\n",
      "[1348 1286 1218 ... 1445 1532 1417]\n"
     ]
    }
   ],
   "source": [
    "predictions = sess.run([output_name], {input_name: input_data})\n",
    "print(len(predictions[0][0]))\n",
    "# 1858 is the the /output/policy shape (batch x 1858) as seen in netron.app\n",
    "print(np.argsort(predictions[0].flatten())[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc79152-b223-4e97-a247-080803600893",
   "metadata": {},
   "source": [
    "Wooo looks like I can get some predicitons out from my input!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f18f9c7-53fd-419a-ab7d-56c53fcfafe0",
   "metadata": {},
   "source": [
    "Now do these mean anything....?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b70d5-893c-41c4-a44a-45b808ad7486",
   "metadata": {},
   "source": [
    "## write something to translate the output into top 3 moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08f6b82-3ff1-46ca-88e6-89c16d1315bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b1a3', 0.00176935363560915),\n",
       " ('b1c3', 0.17127680778503418),\n",
       " ('d1e2', 0.0018413171637803316),\n",
       " ('d1f3', 0.002226013457402587),\n",
       " ('d1g4', 0.0018571442924439907),\n",
       " ('d1h5', 0.0020254654809832573),\n",
       " ('e1e2', 0.0014671743847429752),\n",
       " ('f1e2', 0.01257892046123743),\n",
       " ('f1d3', 0.004621283616870642),\n",
       " ('f1c4', 0.04742936044931412),\n",
       " ('f1b5', 0.003494646167382598),\n",
       " ('f1a6', 0.0016979064093902707),\n",
       " ('g1e2', 0.004234056454151869),\n",
       " ('g1f3', 0.6688069701194763),\n",
       " ('g1h3', 0.0018182129133492708),\n",
       " ('a2a3', 0.010685446672141552),\n",
       " ('a2a4', 0.006090154405683279),\n",
       " ('b2b3', 0.0021589896641671658),\n",
       " ('b2b4', 0.001737439539283514),\n",
       " ('c2c3', 0.004193421453237534),\n",
       " ('c2c4', 0.0030142730101943016),\n",
       " ('d2d3', 0.013650806620717049),\n",
       " ('d2d4', 0.011918947100639343),\n",
       " ('f2f3', 0.0018552218098193407),\n",
       " ('f2f4', 0.0021102826576679945),\n",
       " ('g2g3', 0.0027578608132898808),\n",
       " ('g2g4', 0.001521746045909822),\n",
       " ('h2h3', 0.009272726252675056),\n",
       " ('h2h4', 0.0018878747941926122)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def p_softmax(indicies, p_, p_raw_func):\n",
    "    \"\"\"\n",
    "    Convert raw logits to softmax probabilities.\n",
    "\n",
    "    Args:\n",
    "        indicies (list[int]): List of indices to consider.\n",
    "        p_raw_func (callable): A function that accepts a list of indices and returns the corresponding raw logits.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: Softmax probabilities.\n",
    "    \"\"\"\n",
    "    # Get raw logits for the provided indices\n",
    "    p_vals = np.array(p_raw_func(indicies, p_))\n",
    "    \n",
    "    # Calculate the maximum value for numerical stability\n",
    "    max_p = np.max(p_vals)\n",
    "    \n",
    "    # Calculate exponential values\n",
    "    p_vals = np.exp(p_vals - max_p)\n",
    "    \n",
    "    # Normalize to get probabilities\n",
    "    total = np.sum(p_vals)\n",
    "    if total > 0:\n",
    "        p_vals /= total\n",
    "    \n",
    "    return p_vals.tolist()\n",
    "\n",
    "def p_raw(indicies, p_):\n",
    "    \"\"\"\n",
    "    Extract raw logits from the provided p_ array based on given indices.\n",
    "\n",
    "    Args:\n",
    "        indicies (list[int]): List of indices to consider.\n",
    "        p_ (list[float]): Array containing raw logits or scores.\n",
    "\n",
    "    Returns:\n",
    "        list[float]: Extracted raw logits or scores.\n",
    "    \"\"\"\n",
    "    if any(idx < 0 or idx > 1857 for idx in indicies):\n",
    "        raise ValueError(\"Policy index must be between 0 and 1857.\")\n",
    "    \n",
    "    return [p_[idx] for idx in indicies]\n",
    "    \n",
    "# predictions at 0 since our predictions are batched and we have a batch of 1 here\n",
    "list(zip(g2.moves(), p_softmax(g2.policy_indices(), predictions[0].flatten(), p_raw)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec69871-5e49-4e8f-92bf-8cd73074716a",
   "metadata": {},
   "source": [
    "Great! These look reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e27f1e1-0a6b-4f54-af4c-ea98e5e8ce86",
   "metadata": {},
   "source": [
    "### Let's calculate the true Lc0 output so I can validate that my representations are working correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b37f0b61-3c82-4653-8552-05d1cb232a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('b1a3', 0.0017741298070177436),\n",
       " ('b1c3', 0.17404316365718842),\n",
       " ('d1e2', 0.001867432612925768),\n",
       " ('d1f3', 0.002248866017907858),\n",
       " ('d1g4', 0.0018720037769526243),\n",
       " ('d1h5', 0.0020443403627723455),\n",
       " ('e1e2', 0.0014642218593508005),\n",
       " ('f1e2', 0.01243040431290865),\n",
       " ('f1d3', 0.004636666271835566),\n",
       " ('f1c4', 0.04721570760011673),\n",
       " ('f1b5', 0.003496352816000581),\n",
       " ('f1a6', 0.0017000455409288406),\n",
       " ('g1e2', 0.004145870916545391),\n",
       " ('g1f3', 0.6667669415473938),\n",
       " ('g1h3', 0.0018152031116187572),\n",
       " ('a2a3', 0.010607978329062462),\n",
       " ('a2a4', 0.006029128096997738),\n",
       " ('b2b3', 0.0021638551261276007),\n",
       " ('b2b4', 0.0017414273461326957),\n",
       " ('c2c3', 0.004176905378699303),\n",
       " ('c2c4', 0.003008705098181963),\n",
       " ('d2d3', 0.013671309687197208),\n",
       " ('d2d4', 0.011745461262762547),\n",
       " ('f2f3', 0.0018560135504230857),\n",
       " ('f2f4', 0.002120622666552663),\n",
       " ('g2g3', 0.0027426090091466904),\n",
       " ('g2g4', 0.001520868157967925),\n",
       " ('h2h3', 0.009203264489769936),\n",
       " ('h2h4', 0.0018903155578300357)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_input = GameState(e4e5_board_fen).as_input(b)\n",
    "input = g2.as_input(b)\n",
    "output, _ = b.evaluate(input, dummy_input)\n",
    "list(zip(g2.moves(), output.p_softmax(*g2.policy_indices())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ada8a5b-5fdf-4719-bc58-e20f5d473436",
   "metadata": {},
   "source": [
    "Great! These match!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8afe0-5707-423f-9956-b60f488aea4b",
   "metadata": {},
   "source": [
    "# NMF Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf4b45c-fe9e-4735-9e84-eff81e764503",
   "metadata": {},
   "source": [
    "## Extracting Layers from the model so I can compute the outputs per layer as per the deepmind paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ce7ce1a-0ebf-4cc8-910d-d3ddb4e6bb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/policy (1, 1858)\n",
      "/output/wdl (1, 3)\n",
      "/output/mlh (1, 1)\n",
      "/inputconv (1, 192, 8, 8)\n",
      "/inputconv/relu (1, 192, 8, 8)\n",
      "/block0/conv1 (1, 192, 8, 8)\n",
      "/block0/conv1/relu (1, 192, 8, 8)\n",
      "/block0/conv2 (1, 192, 8, 8)\n",
      "/block0/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block0/conv2/se/squeeze (1, 192)\n",
      "/block0/conv2/se/matmul1 (1, 32)\n",
      "/block0/conv2/se/add1 (1, 32)\n",
      "/block0/conv2/se/relu (1, 32)\n",
      "/block0/conv2/se/matmul2 (1, 384)\n",
      "/block0/conv2/se/add2 (1, 384)\n",
      "/block0/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block0/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block0/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block0/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block0/conv2/se/mul (1, 192, 8, 8)\n",
      "/block0/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block0/conv2/mixin (1, 192, 8, 8)\n",
      "/block0/conv2/relu (1, 192, 8, 8)\n",
      "/block1/conv1 (1, 192, 8, 8)\n",
      "/block1/conv1/relu (1, 192, 8, 8)\n",
      "/block1/conv2 (1, 192, 8, 8)\n",
      "/block1/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block1/conv2/se/squeeze (1, 192)\n",
      "/block1/conv2/se/matmul1 (1, 32)\n",
      "/block1/conv2/se/add1 (1, 32)\n",
      "/block1/conv2/se/relu (1, 32)\n",
      "/block1/conv2/se/matmul2 (1, 384)\n",
      "/block1/conv2/se/add2 (1, 384)\n",
      "/block1/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block1/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block1/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block1/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block1/conv2/se/mul (1, 192, 8, 8)\n",
      "/block1/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block1/conv2/mixin (1, 192, 8, 8)\n",
      "/block1/conv2/relu (1, 192, 8, 8)\n",
      "/block2/conv1 (1, 192, 8, 8)\n",
      "/block2/conv1/relu (1, 192, 8, 8)\n",
      "/block2/conv2 (1, 192, 8, 8)\n",
      "/block2/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block2/conv2/se/squeeze (1, 192)\n",
      "/block2/conv2/se/matmul1 (1, 32)\n",
      "/block2/conv2/se/add1 (1, 32)\n",
      "/block2/conv2/se/relu (1, 32)\n",
      "/block2/conv2/se/matmul2 (1, 384)\n",
      "/block2/conv2/se/add2 (1, 384)\n",
      "/block2/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block2/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block2/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block2/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block2/conv2/se/mul (1, 192, 8, 8)\n",
      "/block2/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block2/conv2/mixin (1, 192, 8, 8)\n",
      "/block2/conv2/relu (1, 192, 8, 8)\n",
      "/block3/conv1 (1, 192, 8, 8)\n",
      "/block3/conv1/relu (1, 192, 8, 8)\n",
      "/block3/conv2 (1, 192, 8, 8)\n",
      "/block3/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block3/conv2/se/squeeze (1, 192)\n",
      "/block3/conv2/se/matmul1 (1, 32)\n",
      "/block3/conv2/se/add1 (1, 32)\n",
      "/block3/conv2/se/relu (1, 32)\n",
      "/block3/conv2/se/matmul2 (1, 384)\n",
      "/block3/conv2/se/add2 (1, 384)\n",
      "/block3/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block3/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block3/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block3/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block3/conv2/se/mul (1, 192, 8, 8)\n",
      "/block3/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block3/conv2/mixin (1, 192, 8, 8)\n",
      "/block3/conv2/relu (1, 192, 8, 8)\n",
      "/block4/conv1 (1, 192, 8, 8)\n",
      "/block4/conv1/relu (1, 192, 8, 8)\n",
      "/block4/conv2 (1, 192, 8, 8)\n",
      "/block4/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block4/conv2/se/squeeze (1, 192)\n",
      "/block4/conv2/se/matmul1 (1, 32)\n",
      "/block4/conv2/se/add1 (1, 32)\n",
      "/block4/conv2/se/relu (1, 32)\n",
      "/block4/conv2/se/matmul2 (1, 384)\n",
      "/block4/conv2/se/add2 (1, 384)\n",
      "/block4/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block4/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block4/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block4/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block4/conv2/se/mul (1, 192, 8, 8)\n",
      "/block4/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block4/conv2/mixin (1, 192, 8, 8)\n",
      "/block4/conv2/relu (1, 192, 8, 8)\n",
      "/block5/conv1 (1, 192, 8, 8)\n",
      "/block5/conv1/relu (1, 192, 8, 8)\n",
      "/block5/conv2 (1, 192, 8, 8)\n",
      "/block5/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block5/conv2/se/squeeze (1, 192)\n",
      "/block5/conv2/se/matmul1 (1, 32)\n",
      "/block5/conv2/se/add1 (1, 32)\n",
      "/block5/conv2/se/relu (1, 32)\n",
      "/block5/conv2/se/matmul2 (1, 384)\n",
      "/block5/conv2/se/add2 (1, 384)\n",
      "/block5/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block5/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block5/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block5/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block5/conv2/se/mul (1, 192, 8, 8)\n",
      "/block5/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block5/conv2/mixin (1, 192, 8, 8)\n",
      "/block5/conv2/relu (1, 192, 8, 8)\n",
      "/block6/conv1 (1, 192, 8, 8)\n",
      "/block6/conv1/relu (1, 192, 8, 8)\n",
      "/block6/conv2 (1, 192, 8, 8)\n",
      "/block6/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block6/conv2/se/squeeze (1, 192)\n",
      "/block6/conv2/se/matmul1 (1, 32)\n",
      "/block6/conv2/se/add1 (1, 32)\n",
      "/block6/conv2/se/relu (1, 32)\n",
      "/block6/conv2/se/matmul2 (1, 384)\n",
      "/block6/conv2/se/add2 (1, 384)\n",
      "/block6/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block6/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block6/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block6/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block6/conv2/se/mul (1, 192, 8, 8)\n",
      "/block6/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block6/conv2/mixin (1, 192, 8, 8)\n",
      "/block6/conv2/relu (1, 192, 8, 8)\n",
      "/block7/conv1 (1, 192, 8, 8)\n",
      "/block7/conv1/relu (1, 192, 8, 8)\n",
      "/block7/conv2 (1, 192, 8, 8)\n",
      "/block7/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block7/conv2/se/squeeze (1, 192)\n",
      "/block7/conv2/se/matmul1 (1, 32)\n",
      "/block7/conv2/se/add1 (1, 32)\n",
      "/block7/conv2/se/relu (1, 32)\n",
      "/block7/conv2/se/matmul2 (1, 384)\n",
      "/block7/conv2/se/add2 (1, 384)\n",
      "/block7/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block7/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block7/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block7/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block7/conv2/se/mul (1, 192, 8, 8)\n",
      "/block7/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block7/conv2/mixin (1, 192, 8, 8)\n",
      "/block7/conv2/relu (1, 192, 8, 8)\n",
      "/block8/conv1 (1, 192, 8, 8)\n",
      "/block8/conv1/relu (1, 192, 8, 8)\n",
      "/block8/conv2 (1, 192, 8, 8)\n",
      "/block8/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block8/conv2/se/squeeze (1, 192)\n",
      "/block8/conv2/se/matmul1 (1, 32)\n",
      "/block8/conv2/se/add1 (1, 32)\n",
      "/block8/conv2/se/relu (1, 32)\n",
      "/block8/conv2/se/matmul2 (1, 384)\n",
      "/block8/conv2/se/add2 (1, 384)\n",
      "/block8/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block8/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block8/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block8/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block8/conv2/se/mul (1, 192, 8, 8)\n",
      "/block8/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block8/conv2/mixin (1, 192, 8, 8)\n",
      "/block8/conv2/relu (1, 192, 8, 8)\n",
      "/block9/conv1 (1, 192, 8, 8)\n",
      "/block9/conv1/relu (1, 192, 8, 8)\n",
      "/block9/conv2 (1, 192, 8, 8)\n",
      "/block9/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block9/conv2/se/squeeze (1, 192)\n",
      "/block9/conv2/se/matmul1 (1, 32)\n",
      "/block9/conv2/se/add1 (1, 32)\n",
      "/block9/conv2/se/relu (1, 32)\n",
      "/block9/conv2/se/matmul2 (1, 384)\n",
      "/block9/conv2/se/add2 (1, 384)\n",
      "/block9/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block9/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block9/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block9/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block9/conv2/se/mul (1, 192, 8, 8)\n",
      "/block9/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block9/conv2/mixin (1, 192, 8, 8)\n",
      "/block9/conv2/relu (1, 192, 8, 8)\n",
      "/block10/conv1 (1, 192, 8, 8)\n",
      "/block10/conv1/relu (1, 192, 8, 8)\n",
      "/block10/conv2 (1, 192, 8, 8)\n",
      "/block10/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block10/conv2/se/squeeze (1, 192)\n",
      "/block10/conv2/se/matmul1 (1, 32)\n",
      "/block10/conv2/se/add1 (1, 32)\n",
      "/block10/conv2/se/relu (1, 32)\n",
      "/block10/conv2/se/matmul2 (1, 384)\n",
      "/block10/conv2/se/add2 (1, 384)\n",
      "/block10/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block10/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block10/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block10/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block10/conv2/se/mul (1, 192, 8, 8)\n",
      "/block10/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block10/conv2/mixin (1, 192, 8, 8)\n",
      "/block10/conv2/relu (1, 192, 8, 8)\n",
      "/block11/conv1 (1, 192, 8, 8)\n",
      "/block11/conv1/relu (1, 192, 8, 8)\n",
      "/block11/conv2 (1, 192, 8, 8)\n",
      "/block11/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block11/conv2/se/squeeze (1, 192)\n",
      "/block11/conv2/se/matmul1 (1, 32)\n",
      "/block11/conv2/se/add1 (1, 32)\n",
      "/block11/conv2/se/relu (1, 32)\n",
      "/block11/conv2/se/matmul2 (1, 384)\n",
      "/block11/conv2/se/add2 (1, 384)\n",
      "/block11/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block11/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block11/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block11/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block11/conv2/se/mul (1, 192, 8, 8)\n",
      "/block11/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block11/conv2/mixin (1, 192, 8, 8)\n",
      "/block11/conv2/relu (1, 192, 8, 8)\n",
      "/block12/conv1 (1, 192, 8, 8)\n",
      "/block12/conv1/relu (1, 192, 8, 8)\n",
      "/block12/conv2 (1, 192, 8, 8)\n",
      "/block12/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block12/conv2/se/squeeze (1, 192)\n",
      "/block12/conv2/se/matmul1 (1, 32)\n",
      "/block12/conv2/se/add1 (1, 32)\n",
      "/block12/conv2/se/relu (1, 32)\n",
      "/block12/conv2/se/matmul2 (1, 384)\n",
      "/block12/conv2/se/add2 (1, 384)\n",
      "/block12/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block12/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block12/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block12/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block12/conv2/se/mul (1, 192, 8, 8)\n",
      "/block12/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block12/conv2/mixin (1, 192, 8, 8)\n",
      "/block12/conv2/relu (1, 192, 8, 8)\n",
      "/block13/conv1 (1, 192, 8, 8)\n",
      "/block13/conv1/relu (1, 192, 8, 8)\n",
      "/block13/conv2 (1, 192, 8, 8)\n",
      "/block13/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block13/conv2/se/squeeze (1, 192)\n",
      "/block13/conv2/se/matmul1 (1, 32)\n",
      "/block13/conv2/se/add1 (1, 32)\n",
      "/block13/conv2/se/relu (1, 32)\n",
      "/block13/conv2/se/matmul2 (1, 384)\n",
      "/block13/conv2/se/add2 (1, 384)\n",
      "/block13/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block13/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block13/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block13/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block13/conv2/se/mul (1, 192, 8, 8)\n",
      "/block13/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block13/conv2/mixin (1, 192, 8, 8)\n",
      "/block13/conv2/relu (1, 192, 8, 8)\n",
      "/block14/conv1 (1, 192, 8, 8)\n",
      "/block14/conv1/relu (1, 192, 8, 8)\n",
      "/block14/conv2 (1, 192, 8, 8)\n",
      "/block14/conv2/se/pooled (1, 192, 1, 1)\n",
      "/block14/conv2/se/squeeze (1, 192)\n",
      "/block14/conv2/se/matmul1 (1, 32)\n",
      "/block14/conv2/se/add1 (1, 32)\n",
      "/block14/conv2/se/relu (1, 32)\n",
      "/block14/conv2/se/matmul2 (1, 384)\n",
      "/block14/conv2/se/add2 (1, 384)\n",
      "/block14/conv2/se/reshape (1, 384, 1, 1)\n",
      "/block14/conv2/se/split/out1 (1, 192, 1, 1)\n",
      "/block14/conv2/se/split/out2 (1, 192, 1, 1)\n",
      "/block14/conv2/se/sigmoid (1, 192, 1, 1)\n",
      "/block14/conv2/se/mul (1, 192, 8, 8)\n",
      "/block14/conv2/se/add3 (1, 192, 8, 8)\n",
      "/block14/conv2/mixin (1, 192, 8, 8)\n",
      "/block14/conv2/relu (1, 192, 8, 8)\n",
      "/policy/conv1 (1, 192, 8, 8)\n",
      "/policy/conv1/relu (1, 192, 8, 8)\n",
      "/policy/conv2 (1, 80, 8, 8)\n",
      "/policy/flatten (1, 5120)\n",
      "/value/conv (1, 32, 8, 8)\n",
      "/value/conv/relu (1, 32, 8, 8)\n",
      "/value/reshape (1, 2048)\n",
      "/value/dense1/matmul (1, 128)\n",
      "/value/dense1/add (1, 128)\n",
      "/value/dense1/relu (1, 128)\n",
      "/value/dense2/matmul (1, 3)\n",
      "/value/dense2/add (1, 3)\n",
      "/mlh/conv (1, 8, 8, 8)\n",
      "/mlh/conv/relu (1, 8, 8, 8)\n",
      "/mlh/reshape (1, 512)\n",
      "/mlh/dense1/matmul (1, 128)\n",
      "/mlh/dense1/add (1, 128)\n",
      "/mlh/dense1/relu (1, 128)\n",
      "/mlh/dense2/matmul (1, 1)\n",
      "/mlh/dense2/add (1, 1)\n",
      "/mlh/dense2/relu (1, 1)\n"
     ]
    }
   ],
   "source": [
    "def onnx_layer_output(onnx_path, dummy_input):\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    org_outputs = [x.name for x in ort_session.get_outputs()]\n",
    "    model = onnx.load(onnx_path)\n",
    "    for node in model.graph.node:\n",
    "        for output in node.output:\n",
    "            if output not in org_outputs:\n",
    "                model.graph.output.extend([onnx.ValueInfoProto(name=output)])\n",
    "    # excute onnx\n",
    "    ort_session = ort.InferenceSession(model.SerializeToString())\n",
    "    outputs = [x.name for x in ort_session.get_outputs()]\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: dummy_input}\n",
    "    ort_outs = ort_session.run(outputs, ort_inputs)\n",
    "    ort_outs = OrderedDict(zip(outputs, ort_outs))\n",
    "    return ort_outs\n",
    "\n",
    "input_data = game_state_to_input_data(g2, b)\n",
    "model_outputs = onnx_layer_output(onnx_path, input_data)\n",
    "for key in model_outputs.keys():\n",
    "    print(key, model_outputs[key].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6484a263-009d-4fd3-a100-e0235e809e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixin = model_outputs[f'/block0/conv2/mixin']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2840908-d7ad-411d-84c5-b2cff9417a92",
   "metadata": {},
   "source": [
    "## Generate FENs from which I can get lots of games to check the activations of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "260421e6-d7a4-4a74-8467-d802742c0cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_BOARD_FEN = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 1\"\n",
    "GAME_OVER_FEN = \"8/1K6/4k3/8/8/8/8/8 b - - 100 500\"\n",
    "ALMOST_OVER_FEN = \"rn2kbnr/ppp2ppp/8/3pp3/2BPP3/2PK4/PP3qPP/RNBb2NR b kq - 0 8\"\n",
    "\n",
    "class ChessGame():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.w = Weights(Lc0_model_path2)\n",
    "        self.b = Backend(weights=w)\n",
    "        self.g = GameState(NEW_BOARD_FEN)\n",
    "        self.moves = []\n",
    "        self.fens = set()\n",
    "        self.setup_model()\n",
    "        self.chess_board = chess.Board(NEW_BOARD_FEN)\n",
    "        self.game_over = False\n",
    "\n",
    "    def setup_model(self):\n",
    "        session_options = ort.SessionOptions()\n",
    "        self.session = ort.InferenceSession(onnx_path, session_options)\n",
    "        self.input_name = self.session.get_inputs()[0].name\n",
    "        self.output_name = self.session.get_outputs()[0].name\n",
    "\n",
    "    def pick_random_weighted_move(self, weighted_options):\n",
    "        # assumes the weights are already normalized\n",
    "        # Create the cumulative distribution\n",
    "        cumulative_distribution = []\n",
    "        cumulative_sum = 0\n",
    "        for option, weight in weighted_options:\n",
    "            cumulative_sum += weight\n",
    "            cumulative_distribution.append((option, cumulative_sum))\n",
    "\n",
    "        # Randomly select\n",
    "        r = random.random()\n",
    "        for option, cumulative_weight in cumulative_distribution:\n",
    "            if r <= cumulative_weight:\n",
    "                # print(f\"Randomly selected option: {option}\")\n",
    "                return option\n",
    "            \n",
    "    def log_fen(self, fen):\n",
    "        self.fens.add(fen)\n",
    "            \n",
    "    def make_move(self, move):\n",
    "        self.moves.append(move)\n",
    "        self.g = GameState(moves=self.moves)\n",
    "\n",
    "        move_obj = self.chess_board.parse_san(move)\n",
    "        self.chess_board.push(move_obj)\n",
    "        self.log_fen(self.chess_board.fen())\n",
    "\n",
    "    def take_turn(self):\n",
    "        input_data = game_state_to_input_data(self.g, self.b)\n",
    "        predictions = self.session.run([self.output_name], {self.input_name: input_data})\n",
    "        move_choices = list(zip(self.g.moves(), p_softmax(self.g.policy_indices(), predictions[0].flatten(), p_raw)))\n",
    "        # print(move_choices)\n",
    "        # print(sorted(move_choices, key=lambda x: x[1]))\n",
    "        move = self.pick_random_weighted_move(move_choices)\n",
    "        self.make_move(move)\n",
    "\n",
    "    def check_game_over(self):\n",
    "        if any([\n",
    "            self.chess_board.is_checkmate(),\n",
    "            self.chess_board.is_stalemate(),\n",
    "            self.chess_board.outcome(),\n",
    "            self.chess_board.can_claim_draw(),\n",
    "            self.chess_board.can_claim_threefold_repetition(),\n",
    "            self.chess_board.can_claim_fifty_moves(),\n",
    "            self.chess_board.is_insufficient_material(),\n",
    "            self.chess_board.is_fivefold_repetition(),\n",
    "            self.chess_board.is_seventyfive_moves(),\n",
    "        ]):\n",
    "            self.game_over = True\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def play_game(self):\n",
    "        for i in range(100):\n",
    "            if not self.check_game_over():\n",
    "                self.take_turn()\n",
    "            else:\n",
    "                return self.fens, self.game_over\n",
    "        return self.fens, self.game_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9043828-76bc-404e-b601-6fb4e40abc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fens():\n",
    "    chess_game = ChessGame()\n",
    "    fens = set()\n",
    "    while len(fens) < 10000:\n",
    "        game_fens, game_over = chess_game.play_game()\n",
    "        fens.update(game_fens)\n",
    "        if game_over:\n",
    "            chess_game = ChessGame()\n",
    "        print(len(fens))\n",
    "    return fens\n",
    "\n",
    "def save_fens(fens):\n",
    "    with open('fens.txt', 'w') as f:\n",
    "        # add a test game that I want to try\n",
    "        f.write(\"r1bqrnk1/pp1p1ppp/2p5/8/3Bp3/6P1/PPP1PPBP/R2QR1K1 b - - 8 27\\n\")\n",
    "        # and continue with the rest of 'em\n",
    "        for fen in fens:\n",
    "            f.write(f\"{fen}\\n\")\n",
    "\n",
    "def load_fens(filename='fens.txt'):\n",
    "    with open(filename, 'r') as f:\n",
    "        fens = f.readlines()\n",
    "    return fens\n",
    "#change to 1 to generate fens again    \n",
    "if 0:\n",
    "    fens = generate_fens()\n",
    "    save_fens(fens)\n",
    "else:\n",
    "    fens = load_fens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77bf7b7b-2bf8-49a1-be0b-a13a6e2f7ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1bqrnk1/pp1p1ppp/2p5/8/3Bp3/6P1/PPP1PPBP/R2QR1K1 b - - 8 27\n",
      "\n",
      "10032\n"
     ]
    }
   ],
   "source": [
    "print(fens[0])\n",
    "print(len(fens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0821197f-83f4-459d-97ae-7e4da6e2456b",
   "metadata": {},
   "source": [
    "## Let's test NMF and see if I understand how the library implementation works on a dummy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03b2ca69-b095-469d-99cd-8fa1103cef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(low=0, high=10, size=(8, 8))\n",
    "from sklearn.decomposition import NMF\n",
    "model = NMF(n_components=36, init='random', random_state=0)\n",
    "W = model.fit_transform(X)\n",
    "H = model.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44184fb9-6005-4026-a6d5-b4c8e4acfd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 8) (8, 36) [[7 8 1 1 9 9 4 0]\n",
      " [2 3 0 7 9 1 0 3]\n",
      " [5 9 8 7 3 8 6 6]\n",
      " [7 5 6 4 9 6 0 4]\n",
      " [9 4 6 4 3 7 4 2]\n",
      " [2 3 3 6 7 7 4 4]\n",
      " [6 3 8 3 4 1 5 5]\n",
      " [2 4 1 4 5 9 6 2]]\n"
     ]
    }
   ],
   "source": [
    "print(H.shape, W.shape, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd786673-1bfe-4558-8987-e4054e408aee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.99974955e+00, 8.00000469e+00, 9.99996934e-01, 1.00022316e+00,\n",
       "        9.00006838e+00, 9.00001457e+00, 3.99992473e+00, 2.33097447e-03],\n",
       "       [1.99992589e+00, 3.00007215e+00, 4.56355943e-03, 6.99994749e+00,\n",
       "        9.00002424e+00, 1.00001064e+00, 1.94989083e-02, 3.00002888e+00],\n",
       "       [4.99997486e+00, 8.99999595e+00, 8.00000350e+00, 7.00000315e+00,\n",
       "        3.00008782e+00, 7.99999904e+00, 6.00000044e+00, 5.99999567e+00],\n",
       "       [7.00006712e+00, 4.99993521e+00, 6.00004448e+00, 4.00004669e+00,\n",
       "        8.99997820e+00, 5.99998991e+00, 1.83884616e-02, 3.99997417e+00],\n",
       "       [9.00000000e+00, 4.00006382e+00, 6.00000000e+00, 4.00000000e+00,\n",
       "        3.00000000e+00, 7.00000000e+00, 4.00000000e+00, 2.00000000e+00],\n",
       "       [2.00028314e+00, 3.00004620e+00, 2.99996015e+00, 5.99996412e+00,\n",
       "        6.99997806e+00, 7.00001096e+00, 3.99999489e+00, 4.00004950e+00],\n",
       "       [6.00002694e+00, 3.00001075e+00, 8.00000765e+00, 3.00002036e+00,\n",
       "        4.00001103e+00, 1.00003374e+00, 5.00000454e+00, 4.99996624e+00],\n",
       "       [2.00054892e+00, 3.99994885e+00, 1.00002040e+00, 4.00001202e+00,\n",
       "        4.99999622e+00, 8.99998562e+00, 6.00001784e+00, 1.99993012e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(W, H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fef9d01-92e5-49c5-931d-1d3302bbcdfd",
   "metadata": {},
   "source": [
    "Okay it looks like it's approximating our thing pretty well. As I increase the number of components the accuracy goes up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84884b99-a0bf-4db7-b477-35031f434f32",
   "metadata": {},
   "source": [
    "## Let's do actual NMF on our model/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da3e29b-9787-4354-8b24-5e4aaee7288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_activations(fen, num_layers):\n",
    "    '''gets all layer activations for a given fen'''\n",
    "    game_state = GameState(fen)\n",
    "    input_data = game_state_to_input_data(game_state, BACKEND)\n",
    "\n",
    "    model_outputs = onnx_layer_output(onnx_path, input_data)\n",
    "    Z_hat_l = {}\n",
    "    for l in range (num_layers):\n",
    "        Z_hat_l[l] = model_outputs[f'/block{l}/conv2/relu']\n",
    "    return Z_hat_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320053dd-2b8b-41af-b7ec-56a39e508927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dimensions\n",
    "H, W, C = 8, 8, 192  # Height, Width, Channels\n",
    "K = 36  # Number of NMF components\n",
    "L = 15  # Number of layers\n",
    "N = len(fens)  # Number of instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16f7be66-08b1-41fb-bad3-436cf26dfbc7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m Z_hat_ls \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# this code take a long time to run, fyi\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fen \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfen\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      6\u001b[0m     Z_hat_l \u001b[38;5;241m=\u001b[39m get_activations(fen, L)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# go through each layer\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "# load all the activations for all the boards\n",
    "Z_hat_ls = {}\n",
    "\n",
    "# this code take a long time to run, fyi\n",
    "for fen in tqdm(fens, desc=\"fen\"):\n",
    "    Z_hat_l = get_activations(fen, L)\n",
    "\n",
    "    # go through each layer\n",
    "    for layer in Z_hat_l:\n",
    "        z_l_flattened = Z_hat_l[layer].reshape(H*W, C)\n",
    "        try:\n",
    "            Z_hat_ls[layer].append(z_l_flattened)\n",
    "        except KeyError:\n",
    "            Z_hat_ls[layer] = []\n",
    "            Z_hat_ls[layer].append(z_l_flattened)\n",
    "\n",
    "for layer in Z_hat_ls:\n",
    "    Z_hat_ls[layer] = np.vstack(Z_hat_ls[layer])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5dd368-1750-459c-bf1e-fc0bdfffb88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_nmf = {}\n",
    "\n",
    "if scipy.sparse.issparse(Z_hat_ls[0]):\n",
    "    algo = \"nndsvd\"\n",
    "else:\n",
    "    algo = \"nndsvda\" # better for sparse matrixes\n",
    "print(f\"Using {algo} as the initialization method.\")\n",
    "\n",
    "for l in tqdm(range(L), desc=\"layer\"): # should be range(L) for final fun\n",
    "    # z_matrices = Z_hat_ls[l]\n",
    "    # Z_hat_l = np.array(z_matrices)  # This will have shape (N, H*W*C)\n",
    "                                    # this SHOULD have shape (NHW x C)\n",
    "    \n",
    "    Z_hat_l = Z_hat_ls[l] # this SHOULD have shape (NHW x C)\n",
    "    print(Z_hat_l.shape)\n",
    "    # (642048, 192) is the shape... this seems right\n",
    "\n",
    "    # Apply NMF to Z_hat_l\n",
    "    # okay looking up frobenius I'm pretty sure that's the right one\n",
    "    nmf = NMF(n_components=K, max_iter=2000, init=algo, solver='cd', beta_loss='frobenius')\n",
    "    nmf_W = nmf.fit_transform(Z_hat_l)  # This will have shape (N, K)\n",
    "    nmf_H = nmf.components_  # This will have shape (K, C)\n",
    "\n",
    "    saved_nmf[f\"nmf_W_{l}\"] = nmf_W\n",
    "    saved_nmf[f\"nmf_H_{l}\"] = nmf_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4d8af0-fcf0-42f6-b271-e639400cd280",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmf.reconstruction_err_) # todo look into this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6f4a00-c35d-4d33-9d1f-6f18506f6e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a file so I don't have to run that big things again\n",
    "with open('nmf_data.pkl', 'wb') as file:\n",
    "    pickle.dump(saved_nmf, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9036b7-d950-4764-a796-bb9fa15fa028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary from the file\n",
    "with open('nmf_data.pkl', 'rb') as file:\n",
    "    nmf_data_loaded = pickle.load(file)\n",
    "    saved_nmf = nmf_data_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb944a0-9cbe-4d05-aa68-6c933097a01a",
   "metadata": {},
   "source": [
    "The shape of nmf_W (which represents the matrix  in the paper) should be designed to reflect the structure of the data it's derived from. Since each row in corresponds to a square on the chessboard and each column to one of the K NMF factors, the shape of nmf_W should be:\n",
    "\n",
    "Number of rows: equal to the number of squares on the chessboard, which is HW. For an 8x8 chessboard, this would be 88=64.\n",
    "Number of columns: equal to the number of NMF factors K that you have decided to use for dimensionality reduction. So if you have K=32 factors, then nmf_W should be a 64x32 matrix. Each row of this matrix corresponds to one of the 64 squares on the chessboard, and each column corresponds to one of the 32 factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d442cc24-876f-425c-9363-3bc8ef5d8a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nmf_W.shape)\n",
    "print(nmf_H.shape)\n",
    "print(len(Z_hat_l[0]))\n",
    "print(Z_hat_l.shape)\n",
    "z_hat_1 = get_activations(e4e5_board_fen, 1)\n",
    "print(z_hat_1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73a13fa-e513-477b-bb50-a51699f6edc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ab8248e-7ed9-442d-8e1a-e2c11045944f",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb19d11-2e30-4d92-839b-99a07f12350e",
   "metadata": {},
   "source": [
    "so since W = omega_all, I want to visualize that\n",
    "To visualize the NMF factors for activations zl, we overlay the K columns of  onto the input z0. The visualization of factor ks contributions to zl is done by reshaping the column k of  into a H W or 88 matrix. The visualization shows how much NMF factor k contributes to each neurons representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e77b6b-c2dd-4c6a-9ae2-e6536330f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_data_to_alpha(grid, color):\n",
    "    # Flatten the grid to make it easier to work with\n",
    "    flat_grid = [item for sublist in grid for item in sublist]\n",
    "    \n",
    "    # Find the min and max values in the grid\n",
    "    min_val = min(flat_grid)\n",
    "    max_val = max(flat_grid)\n",
    "    \n",
    "    # Function to normalize and map values to the 0x00-0xFF range\n",
    "    def normalize(value, min_val, max_val):\n",
    "        # Avoid division by zero if all values in the grid are the same\n",
    "        return int(255 * (value - min_val) / (max_val - min_val)) if max_val != min_val else 0\n",
    "    \n",
    "    # Create the mapping dictionary\n",
    "    alpha_mapping = {}\n",
    "    \n",
    "    for i, value in enumerate(flat_grid):\n",
    "        # Normalize the value to get the alpha equivalent\n",
    "        alpha_hex = format(normalize(value, min_val, max_val), '02X')\n",
    "        # Map the color and alpha to the dictionary\n",
    "        alpha_mapping[i] = f'{color}{alpha_hex}'\n",
    "    \n",
    "    return alpha_mapping\n",
    "\n",
    "color = '#056608'  \n",
    "\n",
    "board = chess.Board(e4e5_board_fen)\n",
    "board.piece_at(62)\n",
    "\n",
    "print(dict.fromkeys(board.attacks(chess.E4)))\n",
    "chess.svg.board(board, size=350, fill=dict.fromkeys(board.attacks(chess.E4), \"#cc0000cc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03339cf5-4e28-463e-90a1-ad78c8266e5e",
   "metadata": {},
   "source": [
    "## single board / block / factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c43298-3e2d-4f9a-bb3c-eaaebde631f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "position_index = 2\n",
    "AlphaZeroExample1_fen= \"r1bqrnk1/pp1p1ppp/2p5/8/3Bp3/6P1/PPP1PPBP/R2QR1K1 b - - 8 27\"\n",
    "board = chess.Board(AlphaZeroExample1_fen)\n",
    "board = chess.Board(fens[position_index])\n",
    "\n",
    "# choose a layer to visualize:\n",
    "layer = 0\n",
    "# Choose a specific factor to visualize\n",
    "factor_index = 0\n",
    "\n",
    "\n",
    "nmf_W = saved_nmf[f\"nmf_W_{layer}\"]\n",
    "nmf_H = saved_nmf[f\"nmf_H_{layer}\"]\n",
    "\n",
    "nmf_W = np.asarray(nmf_W)\n",
    "nmf_W = nmf_W.reshape(N, H, W, K)\n",
    "\n",
    "# Get the weight of this factor for the chosen position\n",
    "factor_weight = nmf_W[position_index, factor_index]\n",
    "\n",
    "# Visualize the contribution\n",
    "print(f'Contribution of Factor {factor_index + 1} to Position {position_index + 1}')\n",
    "alpha_dict = map_data_to_alpha(factor_weight, color)\n",
    "chess.svg.board(board, size=350, fill=alpha_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0315554-4638-498e-a573-44f1b0f6fc38",
   "metadata": {},
   "source": [
    "## All boards / blocks / factors\n",
    "Saves them to files as svg. About a gigabyte for 15 blocks * 36 factors * 50 boards. I should probably compress them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd712828-f0d1-4fa8-8787-501f201d83bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_svg_to_file(svg_data, file_path):\n",
    "    \"\"\"\n",
    "    Saves the SVG representation of a chess board to a file.\n",
    "\n",
    "    :param board: The chess board object.\n",
    "    :param file_path: The path to the file where the SVG will be saved.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(svg_data)\n",
    "\n",
    "all_svgs = []\n",
    "\n",
    "for board_index in range(50):\n",
    "    board = chess.Board(fens[board_index])\n",
    "\n",
    "    for layer in range(L):\n",
    "        nmf_W = saved_nmf[f\"nmf_W_{layer}\"]\n",
    "        nmf_W = np.asarray(nmf_W)\n",
    "        nmf_W = nmf_W.reshape(N, H, W, K)\n",
    "\n",
    "        for factor_index in range(K):\n",
    "            # Get the weight of this factor for the chosen position\n",
    "            # board_weights = nmf_W[board_index]\n",
    "            factor_weight = nmf_W[board_index, :, :, factor_index]\n",
    "\n",
    "            alpha_dict = map_data_to_alpha(factor_weight, color)\n",
    "            svg = chess.svg.board(board, size=350, fill=alpha_dict)\n",
    "            save_svg_to_file(svg, f\"nmf_images/board_{board_index}_layer_{layer}_factor{factor_index}.svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5820fad-4380-4d88-ba78-039f2dec9b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_svg_to_webp(svg_path, webp_path, quality=80):\n",
    "    # Read the SVG file\n",
    "    with open(svg_path, 'rb') as svg_file:\n",
    "        svg_data = svg_file.read()\n",
    "    \n",
    "    # Convert SVG to PNG using cairosvg\n",
    "    png_data = cairosvg.svg2png(bytestring=svg_data)\n",
    "    \n",
    "    # Convert PNG data to an Image object\n",
    "    image = Image.open(io.BytesIO(png_data))\n",
    "    \n",
    "    # Convert Image object to WebP format and save it\n",
    "    image.save(webp_path, 'WEBP', quality=quality)\n",
    "    print(f\"Saved WebP image at {webp_path} with quality {quality}.\")\n",
    "\n",
    "def convert_svgs_in_folder(folder_path, output_folder, quality=80):\n",
    "    # Ensure the output folder exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over all files in the given folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".svg\"):\n",
    "            svg_path = os.path.join(folder_path, filename)\n",
    "            webp_filename = os.path.splitext(filename)[0] + '.webp'\n",
    "            webp_path = os.path.join(output_folder, webp_filename)\n",
    "\n",
    "            # Convert the SVG to WebP\n",
    "            convert_svg_to_webp(svg_path, webp_path, quality)\n",
    "            print(f\"Converted {svg_path} to {webp_path}\")\n",
    "\n",
    "convert_svgs_in_folder('nmf_images', 'nmf_images_compressed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e9471-27a5-4e2c-9458-8c7f0b568d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
